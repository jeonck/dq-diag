"""
ì¼ê´€ì„± ì§„ë‹¨ ëª¨ë“ˆ
Consistency Checker Module

ì†ì„±ëª…, í‘œì¤€ ì¤€ìˆ˜, ì¤‘ë³µê°’, ì—°ê³„ê°’ ë“±ì˜ ì¼ê´€ì„±ì„ ì§„ë‹¨í•©ë‹ˆë‹¤.
"""

import pandas as pd
import numpy as np
import re


class ConsistencyChecker:
    def __init__(self, df):
        self.df = df
        self.name = "ì¼ê´€ì„± (Consistency)"

    def check(self):
        """ì¼ê´€ì„± ì§„ë‹¨ ì‹¤í–‰"""
        issues = []
        metrics = {}

        # 1. ì»¬ëŸ¼ëª… ì¼ê´€ì„± ê²€ì‚¬
        naming_issue = self._check_column_naming()
        if naming_issue:
            issues.append(naming_issue)

        # 2. ë°ì´í„° íƒ€ì… ì¼ê´€ì„± ê²€ì‚¬
        type_issues = self._check_type_consistency()
        issues.extend(type_issues)

        # 3. ì¤‘ë³µ ë°ì´í„° ê²€ì‚¬
        duplicate_issues = self._check_duplicates()
        issues.extend(duplicate_issues)

        # 4. ì½”ë“œê°’ ì¼ê´€ì„± ê²€ì‚¬
        code_issues = self._check_code_consistency()
        issues.extend(code_issues)

        # 5. ë‚ ì§œ í˜•ì‹ ì¼ê´€ì„± ê²€ì‚¬
        date_issues = self._check_date_format_consistency()
        issues.extend(date_issues)

        # ë©”íŠ¸ë¦­ ê³„ì‚°
        duplicate_rate = (self.df.duplicated().sum() / len(self.df) * 100) if len(self.df) > 0 else 0

        # ID ì»¬ëŸ¼ ì¤‘ë³µë¥  ê³„ì‚°
        id_duplicate_rate = 0
        id_cols = [col for col in self.df.columns if any(keyword in col.lower() for keyword in ['id', 'key', 'uuid', 'guid', 'ë²ˆí˜¸', 'no'])]
        if id_cols:
            max_id_dup_rate = 0
            for col in id_cols:
                non_null = self.df[col].dropna()
                if len(non_null) > 0:
                    dup_rate = (non_null.duplicated().sum() / len(non_null) * 100)
                    max_id_dup_rate = max(max_id_dup_rate, dup_rate)
            id_duplicate_rate = max_id_dup_rate

        metrics['ì¤‘ë³µ ë ˆì½”ë“œ ë¹„ìœ¨'] = f"{duplicate_rate:.2f}%"
        metrics['ID ì¤‘ë³µ ë¹„ìœ¨'] = f"{id_duplicate_rate:.2f}%"
        metrics['ì»¬ëŸ¼ ìˆ˜'] = len(self.df.columns)
        metrics['ê³ ìœ  ë ˆì½”ë“œ ìˆ˜'] = f"{len(self.df.drop_duplicates()):,}"

        # ì ìˆ˜ ê³„ì‚° (ID ì¤‘ë³µë¥ ë„ ê³ ë ¤)
        score = self._calculate_score(duplicate_rate, id_duplicate_rate, len(issues))

        return {
            'name': self.name,
            'score': score,
            'issues': issues,
            'metrics': metrics
        }

    def _check_column_naming(self):
        """ì»¬ëŸ¼ëª… ëª…ëª… ê·œì¹™ ê²€ì‚¬"""
        issues_detail = []

        for col in self.df.columns:
            # ê³µë°± í¬í•¨ í™•ì¸
            if ' ' in col:
                issues_detail.append(f"'{col}': ê³µë°± í¬í•¨")

            # íŠ¹ìˆ˜ë¬¸ì í™•ì¸ (ì–¸ë”ìŠ¤ì½”ì–´ ì œì™¸)
            if re.search(r'[^a-zA-Z0-9_ê°€-í£]', col):
                issues_detail.append(f"'{col}': íŠ¹ìˆ˜ë¬¸ì í¬í•¨")

            # ëŒ€ì†Œë¬¸ì í˜¼ìš© í™•ì¸
            if col != col.lower() and col != col.upper():
                if not col.replace('_', '').isalnum():
                    issues_detail.append(f"'{col}': ëŒ€ì†Œë¬¸ì í˜¼ìš©")

        if issues_detail:
            return {
                'title': 'ì»¬ëŸ¼ëª… ëª…ëª… ê·œì¹™ ìœ„ë°˜',
                'severity': 'ğŸŸ¡ ì¤‘ê°„',
                'description': f'{len(issues_detail)}ê°œì˜ ì»¬ëŸ¼ëª…ì´ ëª…ëª… ê·œì¹™ì„ ìœ„ë°˜í•˜ê³  ìˆìŠµë‹ˆë‹¤.',
                'details': {
                    'issues': issues_detail[:10],  # ìµœëŒ€ 10ê°œë§Œ í‘œì‹œ
                    'total_count': len(issues_detail)
                }
            }
        return None

    def _check_type_consistency(self):
        """ë°ì´í„° íƒ€ì… ì¼ê´€ì„± ê²€ì‚¬"""
        issues = []

        # ë™ì¼í•œ ì ‘ë¯¸ì‚¬ë¥¼ ê°€ì§„ ì»¬ëŸ¼ë“¤ì˜ íƒ€ì… ì¼ì¹˜ ì—¬ë¶€ í™•ì¸
        suffix_groups = {}

        for col in self.df.columns:
            # ë‚ ì§œ ê´€ë ¨ ì»¬ëŸ¼
            if any(keyword in col.lower() for keyword in ['date', 'dt', 'ì¼ì', 'ë‚ ì§œ', 'ì‹œê°„']):
                suffix_groups.setdefault('ë‚ ì§œ', []).append((col, self.df[col].dtype))

            # ê¸ˆì•¡ ê´€ë ¨ ì»¬ëŸ¼
            elif any(keyword in col.lower() for keyword in ['amount', 'amt', 'price', 'ê¸ˆì•¡', 'ê°€ê²©']):
                suffix_groups.setdefault('ê¸ˆì•¡', []).append((col, self.df[col].dtype))

            # ì½”ë“œ ê´€ë ¨ ì»¬ëŸ¼
            elif any(keyword in col.lower() for keyword in ['code', 'cd', 'ì½”ë“œ']):
                suffix_groups.setdefault('ì½”ë“œ', []).append((col, self.df[col].dtype))

        # ê° ê·¸ë£¹ ë‚´ì—ì„œ íƒ€ì… ì¼ê´€ì„± í™•ì¸
        for group_name, columns in suffix_groups.items():
            types = set([dtype for _, dtype in columns])
            if len(types) > 1:
                issues.append({
                    'title': f'{group_name} ì»¬ëŸ¼ íƒ€ì… ë¶ˆì¼ì¹˜',
                    'severity': 'ğŸŸ¡ ì¤‘ê°„',
                    'description': f'{group_name} ê´€ë ¨ ì»¬ëŸ¼ë“¤ì´ ì„œë¡œ ë‹¤ë¥¸ ë°ì´í„° íƒ€ì…ì„ ì‚¬ìš©í•˜ê³  ìˆìŠµë‹ˆë‹¤.',
                    'details': {
                        'group': group_name,
                        'columns': [(col, str(dtype)) for col, dtype in columns]
                    }
                })

        # ë™ì¼ ëª…ì¹­ ë‹¤ë¥¸ íƒ€ì…/ê¸¸ì´ ê²€ì‚¬
        # í•µì‹¬ ë‹¨ì–´ ì¶”ì¶œí•˜ì—¬ ìœ ì‚¬í•œ ì»¬ëŸ¼ ê·¸ë£¹í•‘
        from collections import defaultdict
        import re

        # ì»¬ëŸ¼ëª…ì—ì„œ í•µì‹¬ ë‹¨ì–´ ì¶”ì¶œ
        col_info = {}
        for col in self.df.columns:
            # ì–¸ë”ìŠ¤ì½”ì–´ë‚˜ camelCaseë¡œ ë¶„ë¦¬
            words = re.findall(r'[A-Z]?[a-z]+|[A-Z]+(?=[A-Z]|$)|\d+|[ê°€-í£]+', col)
            # ì£¼ìš” ëª…ì‚¬ ì¶”ì¶œ (ì½”ë“œ, ëª…, ëª…ì¹­, id ë“± ì œì™¸í•œ í•µì‹¬ ë‹¨ì–´)
            key_words = [w.lower() for w in words if w.lower() not in ['cd', 'code', 'id', 'no', 'nm', 'name']]

            if key_words:
                key = '_'.join(key_words)
                if key not in col_info:
                    col_info[key] = []

                # íƒ€ì…ê³¼ ê¸¸ì´ ì •ë³´ ì €ì¥
                dtype = self.df[col].dtype
                if dtype == 'object':
                    max_len = self.df[col].astype(str).str.len().max()
                else:
                    max_len = None

                col_info[key].append((col, dtype, max_len))

        # ë™ì¼ í•µì‹¬ ë‹¨ì–´ë¥¼ ê°€ì§„ ì»¬ëŸ¼ë“¤ì˜ íƒ€ì…/ê¸¸ì´ ë¹„êµ
        for key, cols in col_info.items():
            if len(cols) > 1:
                # íƒ€ì… ë¶ˆì¼ì¹˜ ê²€ì‚¬
                types = set([dtype for _, dtype, _ in cols])
                if len(types) > 1:
                    issues.append({
                        'title': f'ìœ ì‚¬ ëª…ì¹­ ì»¬ëŸ¼ì˜ íƒ€ì… ë¶ˆì¼ì¹˜',
                        'severity': 'ğŸŸ¡ ì¤‘ê°„',
                        'description': f'ìœ ì‚¬í•œ ëª…ì¹­ì˜ ì»¬ëŸ¼ë“¤ì´ ì„œë¡œ ë‹¤ë¥¸ ë°ì´í„° íƒ€ì…ì„ ì‚¬ìš©í•˜ê³  ìˆìŠµë‹ˆë‹¤.',
                        'details': {
                            'key_words': key,
                            'columns': [(col, str(dtype), max_len) for col, dtype, max_len in cols]
                        }
                    })

                # ê¸¸ì´ ë¶ˆì¼ì¹˜ ê²€ì‚¬ (ë¬¸ìì—´ ì»¬ëŸ¼ë§Œ)
                str_cols = [(col, max_len) for col, dtype, max_len in cols if dtype == 'object' and max_len]
                if len(str_cols) > 1:
                    lengths = set([max_len for _, max_len in str_cols])
                    if len(lengths) > 1:
                        # ê¸¸ì´ ì°¨ì´ê°€ 2ë°° ì´ìƒì´ë©´ ê²½ê³ 
                        min_len = min(lengths)
                        max_len_val = max(lengths)
                        if max_len_val / min_len >= 2:
                            issues.append({
                                'title': f'ìœ ì‚¬ ëª…ì¹­ ì»¬ëŸ¼ì˜ ê¸¸ì´ ë¶ˆì¼ì¹˜',
                                'severity': 'ğŸŸ¢ ë‚®ìŒ',
                                'description': f'ìœ ì‚¬í•œ ëª…ì¹­ì˜ ë¬¸ìì—´ ì»¬ëŸ¼ë“¤ì´ ì„œë¡œ ë‹¤ë¥¸ ìµœëŒ€ ê¸¸ì´ë¥¼ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤. ({min_len} vs {max_len_val})',
                                'details': {
                                    'key_words': key,
                                    'columns': [(col, max_len) for col, max_len in str_cols],
                                    'min_length': int(min_len),
                                    'max_length': int(max_len_val)
                                }
                            })

        return issues

    def _check_duplicates(self):
        """ì¤‘ë³µ ë°ì´í„° ê²€ì‚¬"""
        issues = []

        # 1. ì „ì²´ ë ˆì½”ë“œ ì¤‘ë³µ ê²€ì‚¬
        duplicate_count = self.df.duplicated().sum()

        if duplicate_count > 0:
            duplicate_rate = (duplicate_count / len(self.df)) * 100

            if duplicate_rate > 10:
                severity = 'ğŸ”´ ë†’ìŒ'
            elif duplicate_rate > 5:
                severity = 'ğŸŸ¡ ì¤‘ê°„'
            else:
                severity = 'ğŸŸ¢ ë‚®ìŒ'

            issues.append({
                'title': 'ì¤‘ë³µ ë ˆì½”ë“œ ë°œê²¬',
                'severity': severity,
                'description': f'ì „ì²´ {len(self.df)}ê±´ ì¤‘ {duplicate_count}ê±´({duplicate_rate:.2f}%)ì´ ì¤‘ë³µì…ë‹ˆë‹¤.',
                'details': {
                    'duplicate_count': int(duplicate_count),
                    'duplicate_rate': round(duplicate_rate, 2),
                    'total_rows': len(self.df)
                }
            })

        # 2. ID/í‚¤ ì»¬ëŸ¼ ì¤‘ë³µ ê²€ì‚¬
        for col in self.df.columns:
            # IDë‚˜ ê³ ìœ  ì‹ë³„ìë¡œ ì¶”ì •ë˜ëŠ” ì»¬ëŸ¼
            if any(keyword in col.lower() for keyword in ['id', 'key', 'uuid', 'guid', 'ë²ˆí˜¸', 'no', 'code', 'cd']):
                # NULL ì œì™¸í•˜ê³  ì¤‘ë³µ í™•ì¸
                non_null = self.df[col].dropna()
                if len(non_null) > 0:
                    dup_count = non_null.duplicated().sum()
                    if dup_count > 0:
                        dup_rate = (dup_count / len(non_null)) * 100

                        if dup_rate > 10:
                            severity = 'ğŸ”´ ë†’ìŒ'
                        elif dup_rate > 5:
                            severity = 'ğŸŸ¡ ì¤‘ê°„'
                        else:
                            severity = 'ğŸŸ¢ ë‚®ìŒ'

                        # ì¤‘ë³µëœ ê°’ë“¤ í™•ì¸
                        dup_values = non_null[non_null.duplicated(keep=False)].value_counts()

                        issues.append({
                            'title': f'ì»¬ëŸ¼ "{col}"ì—ì„œ ì¤‘ë³µ ID ë°œê²¬',
                            'severity': severity,
                            'description': f'ê³ ìœ í•´ì•¼ í•  ID ì»¬ëŸ¼ì—ì„œ {dup_count}ê±´({dup_rate:.2f}%)ì˜ ì¤‘ë³µì´ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤.',
                            'details': {
                                'column': col,
                                'duplicate_count': int(dup_count),
                                'duplicate_rate': round(dup_rate, 2),
                                'duplicate_values': {str(k): int(v) for k, v in dup_values.head(5).items()}
                            }
                        })

        return issues

    def _check_code_consistency(self):
        """ì½”ë“œê°’ ì¼ê´€ì„± ê²€ì‚¬"""
        issues = []

        for col in self.df.columns:
            # ì½”ë“œ ì»¬ëŸ¼ìœ¼ë¡œ ì¶”ì •ë˜ëŠ” ê²½ìš°
            if any(keyword in col.lower() for keyword in ['code', 'cd', 'ì½”ë“œ', 'yn', 'ì—¬ë¶€', 'êµ¬ë¶„']):
                unique_values = self.df[col].dropna().unique()

                # ìœ ë‹ˆí¬ ê°’ì´ ë„ˆë¬´ ë§ìœ¼ë©´ ìŠ¤í‚µ (ì½”ë“œ ì»¬ëŸ¼ì´ ì•„ë‹ ê°€ëŠ¥ì„±)
                if len(unique_values) > 20:
                    continue

                # ëŒ€ì†Œë¬¸ì í˜¼ìš© í™•ì¸
                if self.df[col].dtype == 'object':
                    values_lower = set([str(v).lower() for v in unique_values])
                    if len(values_lower) < len(unique_values):
                        issues.append({
                            'title': f'ì»¬ëŸ¼ "{col}"ì˜ ì½”ë“œê°’ ëŒ€ì†Œë¬¸ì ë¶ˆì¼ì¹˜',
                            'severity': 'ğŸŸ¡ ì¤‘ê°„',
                            'description': 'ë™ì¼í•œ ì½”ë“œê°’ì´ ëŒ€ì†Œë¬¸ìë¥¼ ë‹¬ë¦¬í•˜ì—¬ ì €ì¥ë˜ì–´ ìˆìŠµë‹ˆë‹¤.',
                            'details': {
                                'column': col,
                                'unique_values': list(unique_values)[:20]
                            }
                        })

        return issues

    def _check_date_format_consistency(self):
        """ë‚ ì§œ í˜•ì‹ ì¼ê´€ì„± ê²€ì‚¬"""
        issues = []

        for col in self.df.columns:
            # ë‚ ì§œ ì»¬ëŸ¼ìœ¼ë¡œ ì¶”ì •ë˜ëŠ” ê²½ìš°
            if any(keyword in col.lower() for keyword in ['date', 'dt', 'ì¼ì', 'ë‚ ì§œ']):

                if self.df[col].dtype == 'object':
                    # NULLì´ ì•„ë‹Œ ê°’ë“¤ì˜ í˜•ì‹ í™•ì¸
                    non_null_values = self.df[col].dropna().astype(str)

                    if len(non_null_values) == 0:
                        continue

                    # ë‹¤ì–‘í•œ ë‚ ì§œ í˜•ì‹ íŒ¨í„´
                    formats = {
                        'YYYY-MM-DD': r'^\d{4}-\d{2}-\d{2}',
                        'YYYY/MM/DD': r'^\d{4}/\d{2}/\d{2}',
                        'YYYYMMDD': r'^\d{8}$',
                        'DD-MM-YYYY': r'^\d{2}-\d{2}-\d{4}',
                        'DD/MM/YYYY': r'^\d{2}/\d{2}/\d{4}'
                    }

                    format_counts = {}
                    for format_name, pattern in formats.items():
                        count = non_null_values.str.match(pattern).sum()
                        if count > 0:
                            format_counts[format_name] = count

                    # ì—¬ëŸ¬ í˜•ì‹ì´ í˜¼ìš©ë˜ëŠ” ê²½ìš°
                    if len(format_counts) > 1:
                        issues.append({
                            'title': f'ì»¬ëŸ¼ "{col}"ì˜ ë‚ ì§œ í˜•ì‹ ë¶ˆì¼ì¹˜',
                            'severity': 'ğŸŸ¡ ì¤‘ê°„',
                            'description': 'ì—¬ëŸ¬ ê°€ì§€ ë‚ ì§œ í˜•ì‹ì´ í˜¼ìš©ë˜ì–´ ìˆìŠµë‹ˆë‹¤.',
                            'details': {
                                'column': col,
                                'format_counts': format_counts
                            }
                        })

        return issues

    def _calculate_score(self, duplicate_rate, id_duplicate_rate, issue_count):
        """ì ìˆ˜ ê³„ì‚° (ì—„ê²©í•œ ê¸°ì¤€)"""
        # ë ˆì½”ë“œ ì¤‘ë³µë¥  ê¸°ë°˜ ì ìˆ˜ (25%)
        duplicate_score = max(0, 100 - duplicate_rate * 5) * 0.25

        # ID ì¤‘ë³µë¥  ê¸°ë°˜ ì ìˆ˜ (25%) - ID ì¤‘ë³µì€ ë”ìš± ì¹˜ëª…ì 
        id_duplicate_score = max(0, 100 - id_duplicate_rate * 10) * 0.25

        # ì´ìŠˆ ê°œìˆ˜ ê¸°ë°˜ ê°ì  (50%)
        # ì´ìŠˆë‹¹ ë” í° ê°ì  ì ìš©
        issue_penalty = min(issue_count * 10, 50)
        issue_score = 50 - issue_penalty

        total_score = duplicate_score + id_duplicate_score + issue_score

        # ì¤‘ë³µë¥ ì´ 20% ì´ìƒì´ë©´ ì¶”ê°€ ê°ì 
        if duplicate_rate >= 20 or id_duplicate_rate >= 20:
            total_score *= 0.5
        # ì¤‘ë³µë¥ ì´ 10% ì´ìƒì´ë©´ ì¶”ê°€ ê°ì 
        elif duplicate_rate >= 10 or id_duplicate_rate >= 10:
            total_score *= 0.7

        return round(max(0, total_score), 2)
