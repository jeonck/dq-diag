"""
ì™„ì „ì„± ì§„ë‹¨ ëª¨ë“ˆ
Completeness Checker Module

ë°ì´í„° ëª¨ë¸ì˜ ì™„ì „ì„±, ì‹ë³„ì, ë¬¼ë¦¬êµ¬ì¡°, ì†ì„±ì˜ë¯¸ ë“±ì„ ì§„ë‹¨í•©ë‹ˆë‹¤.
"""

import pandas as pd
import numpy as np
from modules.utils import safe_outlier_detection, calculate_uniqueness_metrics


class CompletenessChecker:
    def __init__(self, df):
        self.df = df
        self.name = "ì™„ì „ì„± (Completeness)"

    def check(self):
        """ì™„ì „ì„± ì§„ë‹¨ ì‹¤í–‰"""
        issues = []
        metrics = {}

        # 1. ê¸°ë³¸í‚¤(PK) ë¯¸ì •ì˜ ê²€ì‚¬
        pk_issue = self._check_primary_key()
        if pk_issue:
            issues.append(pk_issue)

        # 2. í•„ìˆ˜ê°’ ì™„ì „ì„± ê²€ì‚¬
        null_issues = self._check_null_values()
        issues.extend(null_issues)

        # 3. ë¯¸ì‚¬ìš© ì»¬ëŸ¼ ê²€ì‚¬
        unused_cols = self._check_unused_columns()
        if unused_cols:
            issues.append(unused_cols)

        # 4. ë°ì´í„° íƒ€ì… ì¼ì¹˜ì„± ê²€ì‚¬
        type_issue = self._check_data_types()
        if type_issue:
            issues.append(type_issue)

        # 5. ì´ìƒì¹˜ ê²€ì‚¬ (ì¶”ê°€)
        outlier_issues = self._check_outliers()
        issues.extend(outlier_issues)

        # ë©”íŠ¸ë¦­ ê³„ì‚°
        total_cells = len(self.df) * len(self.df.columns)
        null_cells = self.df.isnull().sum().sum()
        completeness_rate = ((total_cells - null_cells) / total_cells * 100) if total_cells > 0 else 0

        metrics['ì™„ì „ì„± ë¹„ìœ¨'] = f"{completeness_rate:.2f}%"
        metrics['NULL ì…€ ìˆ˜'] = f"{null_cells:,}"
        metrics['ì „ì²´ ì…€ ìˆ˜'] = f"{total_cells:,}"

        # ì ìˆ˜ ê³„ì‚° (100ì  ë§Œì )
        score = self._calculate_score(completeness_rate, len(issues))

        return {
            'name': self.name,
            'score': score,
            'issues': issues,
            'metrics': metrics
        }

    def _check_primary_key(self):
        """ê¸°ë³¸í‚¤ ì¡´ì¬ ì—¬ë¶€ í™•ì¸"""
        # ëª¨ë“  í–‰ì´ ìœ ì¼í•œì§€ í™•ì¸
        duplicate_rows = self.df.duplicated().sum()

        if duplicate_rows > 0:
            return {
                'title': 'ê¸°ë³¸í‚¤ ë¯¸ì •ì˜ ë˜ëŠ” ì¤‘ë³µ ë ˆì½”ë“œ',
                'severity': 'ğŸ”´ ë†’ìŒ',
                'description': f'ì¤‘ë³µëœ ë ˆì½”ë“œê°€ {duplicate_rows}ê±´ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤. ê° ë ˆì½”ë“œë¥¼ ìœ ì¼í•˜ê²Œ êµ¬ë¶„í•  ìˆ˜ ìˆëŠ” ì‹ë³„ìê°€ í•„ìš”í•©ë‹ˆë‹¤.',
                'details': {
                    'duplicate_count': int(duplicate_rows),
                    'total_rows': len(self.df)
                }
            }
        return None

    def _check_null_values(self):
        """NULL ê°’ ë° ê³µë°± ê°’ ê²€ì‚¬"""
        issues = []

        null_summary = self.df.isnull().sum()
        null_cols = null_summary[null_summary > 0]

        for col, null_count in null_cols.items():
            null_rate = (null_count / len(self.df)) * 100

            # NULLê³¼ Space í˜¼ì¬ ê²€ì‚¬ (ë¬¸ìì—´ ì»¬ëŸ¼ë§Œ)
            space_count = 0
            if self.df[col].dtype == 'object':
                # ë¹ˆ ë¬¸ìì—´, ê³µë°±ë§Œ ìˆëŠ” ë¬¸ìì—´ ê²€ì‚¬
                space_count = (self.df[col].fillna('').str.strip() == '').sum() - null_count

                # NULLê³¼ Spaceê°€ ëª¨ë‘ ì¡´ì¬í•˜ë©´ í˜¼ì¬ ê²½ê³ 
                if null_count > 0 and space_count > 0:
                    total_empty = null_count + space_count
                    empty_rate = (total_empty / len(self.df)) * 100

                    issues.append({
                        'title': f'ì»¬ëŸ¼ "{col}"ì— NULLê³¼ ê³µë°± í˜¼ì¬',
                        'severity': 'ğŸ”´ ë†’ìŒ',
                        'description': f'NULL {null_count}ê±´, ê³µë°± {space_count}ê±´ìœ¼ë¡œ ì´ {total_empty}ê±´({empty_rate:.2f}%)ì˜ ë¹ˆ ê°’ì´ í˜¼ì¬ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ë°ì´í„° ì¼ê´€ì„±ì„ ìœ„í•´ í†µì¼ì´ í•„ìš”í•©ë‹ˆë‹¤.',
                        'details': {
                            'column': col,
                            'null_count': int(null_count),
                            'space_count': int(space_count),
                            'total_empty': int(total_empty),
                            'empty_rate': round(empty_rate, 2),
                            'total_rows': len(self.df)
                        }
                    })
                    continue  # NULLê³¼ Space í˜¼ì¬ ì´ìŠˆë¥¼ ë³´ê³ í–ˆìœ¼ë©´ ê°œë³„ NULL ì´ìŠˆëŠ” ìŠ¤í‚µ

            # ì¼ë°˜ NULL ê°’ ì´ìŠˆ
            if null_rate > 50:
                severity = 'ğŸ”´ ë†’ìŒ'
            elif null_rate > 20:
                severity = 'ğŸŸ¡ ì¤‘ê°„'
            else:
                severity = 'ğŸŸ¢ ë‚®ìŒ'

            # ê³µë°±ë§Œ ìˆëŠ” ê²½ìš° í¬í•¨
            total_missing = null_count + space_count
            missing_rate = (total_missing / len(self.df)) * 100

            desc_parts = [f'ì „ì²´ {len(self.df)}ê±´ ì¤‘']
            if null_count > 0:
                desc_parts.append(f'NULL {null_count}ê±´')
            if space_count > 0:
                desc_parts.append(f'ê³µë°± {space_count}ê±´')
            desc_parts.append(f'(ì´ {missing_rate:.2f}%)')

            issues.append({
                'title': f'ì»¬ëŸ¼ "{col}"ì˜ í•„ìˆ˜ê°’ ëˆ„ë½',
                'severity': severity,
                'description': ' '.join(desc_parts) + 'ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤.',
                'details': {
                    'column': col,
                    'null_count': int(null_count),
                    'space_count': int(space_count),
                    'total_missing': int(total_missing),
                    'missing_rate': round(missing_rate, 2),
                    'total_rows': len(self.df)
                }
            })

        return issues

    def _check_unused_columns(self):
        """ë¯¸ì‚¬ìš© ì»¬ëŸ¼ ê²€ì‚¬"""
        unused_cols = []

        for col in self.df.columns:
            # ëª¨ë“  ê°’ì´ NULLì¸ ì»¬ëŸ¼
            if self.df[col].isnull().all():
                unused_cols.append(col)
            # ëª¨ë“  ê°’ì´ ë™ì¼í•œ ì»¬ëŸ¼
            elif self.df[col].nunique() <= 1:
                unused_cols.append(col)

        if unused_cols:
            return {
                'title': 'ë¯¸ì‚¬ìš© ë˜ëŠ” ë¬´ì˜ë¯¸í•œ ì»¬ëŸ¼ ë°œê²¬',
                'severity': 'ğŸŸ¡ ì¤‘ê°„',
                'description': f'{len(unused_cols)}ê°œì˜ ë¯¸ì‚¬ìš© ì»¬ëŸ¼ì´ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤.',
                'details': {
                    'unused_columns': unused_cols,
                    'count': len(unused_cols)
                }
            }
        return None

    def _check_data_types(self):
        """ë°ì´í„° íƒ€ì… ì¼ì¹˜ì„± ê²€ì‚¬"""
        type_issues = []

        for col in self.df.columns:
            # ìˆ«ìí˜•ìœ¼ë¡œ ë³´ì´ëŠ” ì»¬ëŸ¼ì´ ë¬¸ìí˜•ì¸ ê²½ìš°
            if self.df[col].dtype == 'object':
                # NULLì´ ì•„ë‹Œ ê°’ë“¤ ì¤‘ ìˆ«ìë¡œ ë³€í™˜ ê°€ëŠ¥í•œì§€ í™•ì¸
                non_null_values = self.df[col].dropna()
                if len(non_null_values) > 0:
                    try:
                        pd.to_numeric(non_null_values)
                        type_issues.append(col)
                    except:
                        pass

        if type_issues:
            return {
                'title': 'ë°ì´í„° íƒ€ì… ë¶ˆì¼ì¹˜',
                'severity': 'ğŸŸ¡ ì¤‘ê°„',
                'description': f'{len(type_issues)}ê°œì˜ ì»¬ëŸ¼ì´ ìˆ«ìí˜•ìœ¼ë¡œ ë³€í™˜ ê°€ëŠ¥í•˜ë‚˜ ë¬¸ìí˜•ìœ¼ë¡œ ì €ì¥ë˜ì–´ ìˆìŠµë‹ˆë‹¤.',
                'details': {
                    'columns': type_issues,
                    'count': len(type_issues)
                }
            }
        return None

    def _check_outliers(self):
        """ì´ìƒì¹˜ ê²€ì‚¬ (IQR ë°©ë²• + Z-score ë°©ë²•)"""
        issues = []

        for col in self.df.columns:
            if pd.api.types.is_numeric_dtype(self.df[col]):
                # IQR ë°©ë²•
                outliers_iqr = safe_outlier_detection(self.df[col])

                # Z-score ë°©ë²• (ë” ë¯¼ê°í•œ íƒì§€)
                non_null = self.df[col].dropna()
                if len(non_null) > 3:
                    mean_val = non_null.mean()
                    std_val = non_null.std()

                    if std_val and std_val != 0:
                        z_scores = ((non_null - mean_val) / std_val).abs()
                        # ë°ì´í„°ê°€ ì‘ì„ìˆ˜ë¡ ë” ë¯¼ê°í•˜ê²Œ (10ê°œ ì´í•˜ë©´ 1.5, ê·¸ ì´ìƒì´ë©´ 2.0)
                        threshold = 1.5 if len(non_null) <= 10 else 2.0
                        outliers_z = non_null[z_scores > threshold]
                    else:
                        outliers_z = pd.Series(dtype=float)
                else:
                    outliers_z = pd.Series(dtype=float)

                # ë‘ ë°©ë²• ì¤‘ í•˜ë‚˜ë¼ë„ íƒì§€ë˜ë©´ ë³´ê³ 
                if isinstance(outliers_iqr, pd.Series) and len(outliers_iqr) > 0:
                    outlier_rate = (len(outliers_iqr) / len(self.df)) * 100

                    if outlier_rate > 10:
                        severity = 'ğŸ”´ ë†’ìŒ'
                    elif outlier_rate > 5:
                        severity = 'ğŸŸ¡ ì¤‘ê°„'
                    else:
                        severity = 'ğŸŸ¢ ë‚®ìŒ'

                    issues.append({
                        'title': f'ì»¬ëŸ¼ "{col}"ì—ì„œ ì´ìƒì¹˜ ë°œê²¬ (IQR ë°©ë²•)',
                        'severity': severity,
                        'description': f'IQR ë°©ë²•ìœ¼ë¡œ {len(outliers_iqr)}ê±´({outlier_rate:.2f}%)ì˜ ì´ìƒì¹˜ê°€ íƒì§€ë˜ì—ˆìŠµë‹ˆë‹¤.',
                        'details': {
                            'column': col,
                            'method': 'IQR',
                            'outlier_count': len(outliers_iqr),
                            'outlier_rate': round(outlier_rate, 2),
                            'outlier_values': list(outliers_iqr.head(10))
                        }
                    })
                elif len(outliers_z) > 0:
                    # IQRë¡œ íƒì§€ ì•ˆë˜ë©´ Z-scoreë¡œ íƒì§€
                    outlier_rate = (len(outliers_z) / len(self.df)) * 100

                    if outlier_rate > 10:
                        severity = 'ğŸ”´ ë†’ìŒ'
                    elif outlier_rate > 5:
                        severity = 'ğŸŸ¡ ì¤‘ê°„'
                    else:
                        severity = 'ğŸŸ¢ ë‚®ìŒ'

                    issues.append({
                        'title': f'ì»¬ëŸ¼ "{col}"ì—ì„œ ì´ìƒì¹˜ ë°œê²¬ (Z-score ë°©ë²•)',
                        'severity': severity,
                        'description': f'Z-score ë°©ë²•ìœ¼ë¡œ {len(outliers_z)}ê±´({outlier_rate:.2f}%)ì˜ ì´ìƒì¹˜ê°€ íƒì§€ë˜ì—ˆìŠµë‹ˆë‹¤. (í‰ê· : {mean_val:.1f}, í‘œì¤€í¸ì°¨: {std_val:.1f})',
                        'details': {
                            'column': col,
                            'method': 'Z-score',
                            'outlier_count': len(outliers_z),
                            'outlier_rate': round(outlier_rate, 2),
                            'outlier_values': list(outliers_z.head(10)),
                            'mean': round(mean_val, 2),
                            'std': round(std_val, 2)
                        }
                    })

        return issues

    def _calculate_score(self, completeness_rate, issue_count):
        """ì ìˆ˜ ê³„ì‚° (ì—„ê²©í•œ ê¸°ì¤€)"""
        # ì™„ì „ì„± ë¹„ìœ¨ ê¸°ë°˜ ì ìˆ˜ (60%)
        base_score = completeness_rate * 0.6

        # ì´ìŠˆ ê°œìˆ˜ ê¸°ë°˜ ê°ì  (40%)
        # ì´ìŠˆë‹¹ ë” í° ê°ì  ì ìš©
        issue_penalty = min(issue_count * 8, 40)
        issue_score = 40 - issue_penalty

        total_score = base_score + issue_score

        # ì™„ì „ì„± ë¹„ìœ¨ì´ 50% ë¯¸ë§Œì´ë©´ ì¶”ê°€ ê°ì 
        if completeness_rate < 50:
            total_score *= 0.5

        # ì™„ì „ì„± ë¹„ìœ¨ì´ 70% ë¯¸ë§Œì´ë©´ ì¶”ê°€ ê°ì 
        elif completeness_rate < 70:
            total_score *= 0.7

        return round(max(0, total_score), 2)
